<!DOCTYPE html>
<html lang="en" dir="ltr" class="client-nojs">"
<p><b>Space-time trade-off</b> («выбор оптимального соотношения „место-время“ (англ. <i>space-time trade-off</i>)», или, иначе, «выбор оптимального соотношения „время-память“» (англ. <i>time-memory trade-off</i>)) — компромиссный подход к решению ряда задач в информатике, при котором требуемый объем памяти может быть снижен за счет более медленного выполнения программы (или, наоборот, время вычислений может быть снижено за счет увеличения объема используемой памяти).</p>
<p>Благодаря уменьшению относительных расходов на объем ОЗУ (RAM) и памяти на жестком диске (в течение некоторого периода времени стоимость места на жестком диске дешевела значительно быстрее, чем стоимость других компонент ЭВМ), постепенное распространение получали приемы, использующие доступную память для уменьшения времени вычислений. В то же время, такие приемы, как архивация данных, демонстрируют альтернативный подход — экономное использование памяти за счет дополнительных преобразований данных из одного формата в другой.</p>
<table id="toc" class="toc" summary="Contents">
<tr>
<td>
<div id="toctitle">
<h2>Contents</h2>
</div>
<ul>
<ul>
<li class="toclevel-1"><a href="#.D0.9F.D1.80.D0.B8.D0.BC.D0.B5.D1.80.D1.8B_.D0.BF.D1.80.D0.B8.D0.BC.D0.B5.D0.BD.D0.B5.D0.BD.D0.B8.D1.8F">Примеры применения</a>
</li>
<ul>
<li class="toclevel-2"><a href="#.D0.A2.D0.B0.D0.B1.D0.BB.D0.B8.D1.86.D1.8B_.D0.BF.D0.BE.D0.B8.D1.81.D0.BA.D0.B0">Таблицы поиска</a>
</li>
<li class="toclevel-2"><a href="#.D0.A1.D0.B6.D0.B0.D1.82.D0.B8.D0.B5_.D0.B4.D0.B0.D0.BD.D0.BD.D1.8B.D1.85">Сжатие данных</a>
</li>
<li class="toclevel-2"><a href="#.D0.A0.D0.B0.D1.81.D0.BA.D1.80.D1.83.D1.82.D0.BA.D0.B0_.D1.86.D0.B8.D0.BA.D0.BB.D0.B0">Раскрутка цикла</a>
</li>
</ul>
<li class="toclevel-1"><a href="#.D0.9A.D1.80.D0.B8.D0.BF.D1.82.D0.BE.D0.B3.D1.80.D0.B0.D1.84.D0.B8.D1.8F">Криптография</a>
</li>
<ul>
<li class="toclevel-2"><a href="#.D0.9C.D0.B5.D1.82.D0.BE.D0.B4.2C_.D0.BF.D1.80.D0.B5.D0.B4.D0.BB.D0.BE.D0.B6.D0.B5.D0.BD.D0.BD.D1.8B.D0.B9_.D0.A5.D0.B5.D0.BB.D0.BB.D0.BC.D0.B0.D0.BD.D0.BE.D0.BC">Метод, предложенный Хеллманом</a>
</li>
</ul>
<li class="toclevel-1"><a href="#.D0.94.D1.80.D1.83.D0.B3.D0.B8.D0.B5_.D0.BF.D1.80.D0.B8.D0.BC.D0.B5.D1.80.D1.8B">Другие примеры</a>
</li>
<li class="toclevel-1"><a href="#.D0.A1.D0.BC._.D1.82.D0.B0.D0.BA.D0.B6.D0.B5">См. также</a>
</li>
<li class="toclevel-1"><a href="#.D0.9F.D1.80.D0.B8.D0.BC.D0.B5.D1.87.D0.B0.D0.BD.D0.B8.D1.8F">Примечания</a>
</li>
<li class="toclevel-1"><a href="#.D0.A1.D1.81.D1.8B.D0.BB.D0.BA.D0.B8">Ссылки</a>
</li>
</ul>
</ul></td></tr></table><hr/>
<h2><span class="mw-headline" id=".D0.9F.D1.80.D0.B8.D0.BC.D0.B5.D1.80.D1.8B_.D0.BF.D1.80.D0.B8.D0.BC.D0.B5.D0.BD.D0.B5.D0.BD.D0.B8.D1.8F">Примеры применения</span></h2>

<h3><span class="mw-headline" id=".D0.A2.D0.B0.D0.B1.D0.BB.D0.B8.D1.86.D1.8B_.D0.BF.D0.BE.D0.B8.D1.81.D0.BA.D0.B0">Таблицы поиска</span></h3>
<p>Многие задачи поиска, такие как непрерывная задача о рюкзаке, задача о дискретном логарифме или задача обращения односторонней функции, решаясь, по сути, перебором, допускают в то же время использование т. н. таблиц поиска (англ. <i>lookup tables</i>). Идея такова: вместо того, чтобы, не используя дополнительную память, перебирать все допустимые решения, или один развычислить их все заранее и хранить их в памяти (часто нет ни первой, ни второй возможности), можно заранее вычислить <i>часть</i> допустимых значений, и, организовав их в специальную структуру данных — таблицу поиска, — осуществлять с ее помощью дальнейший перебор уже непосредственно при решении задачи.</p>
<p>Применению данного подхода в криптографии посвящен отдельный раздел данной статьи.</p>
<h3><span class="mw-headline" id=".D0.A1.D0.B6.D0.B0.D1.82.D0.B8.D0.B5_.D0.B4.D0.B0.D0.BD.D0.BD.D1.8B.D1.85">Сжатие данных</span></h3>
<p>Выбор оптимального соотношения место-время может быть применён и к проблеме хранения данных. Хранение данных в несжатом виде потребует большего объема памяти, но на их извлечение понадобится меньше времени, чем на извлечение данных, хранящихся в сжатом виде. В зависимости от конкретной задачи может быть предпочтителен тот или иной вариант.</p>
<p>Классическим примером сжатого хранения данных может служить, к примеру, формат представления формул <b><i>&#39;</i></b>, используемый для написания научных статей. Результатом работы пользователя является файл специального формата, который при необходимости легко может быть преобразован в гораздо более «тяжеловесный» pdf-файл, который, в свою очередь, уже может быть использован для просмотра документа.</p>
<h3><span class="mw-headline" id=".D0.A0.D0.B0.D1.81.D0.BA.D1.80.D1.83.D1.82.D0.BA.D0.B0_.D1.86.D0.B8.D0.BA.D0.BB.D0.B0">Раскрутка цикла</span></h3>

<p>Раскрутка цикла (англ. <i>loop unwindling</i>) является весьма популярным приемом оптимизации кода, используемым во многих компиляторах. Идея состоит в увеличении числа инструкций, исполняемых в течение одной итерации цикла. В результате уменьшается число итераций (в пределе до единицы: все инструкции исполняются одна за другой), что, в свою очередь, увеличивает эффективность работы кэша данных.</p>
<h2><span class="mw-headline" id=".D0.9A.D1.80.D0.B8.D0.BF.D1.82.D0.BE.D0.B3.D1.80.D0.B0.D1.84.D0.B8.D1.8F">Криптография</span></h2>
<p>В данном разделе рассмотрен классический пример использования подхода Space-Time Trade-Off в криптографии — применение таблиц поиска в решении криптографической проблемы обращения криптографической хеш-функции.</p>
<p>Криптоаналитический перебор требует значительных вычислительных затрат. В случае, если требуется многократно осуществлять взлом криптосистемы, логично было бы заранее выполнить исчерпывающий перебор и хранить вычисленные значения в памяти. Сделав это однократно, можно далее осуществлять перебор практически мгновенно.
Впрочем, в реальности этот метод неприменим из-за огромных затрат памяти.</p>
<h3><span class="mw-headline" id=".D0.9C.D0.B5.D1.82.D0.BE.D0.B4.2C_.D0.BF.D1.80.D0.B5.D0.B4.D0.BB.D0.BE.D0.B6.D0.B5.D0.BD.D0.BD.D1.8B.D0.B9_.D0.A5.D0.B5.D0.BB.D0.BB.D0.BC.D0.B0.D0.BD.D0.BE.D0.BC">Метод, предложенный Хеллманом</span></h3>

<p>В 1980 году Мартин Хеллман предложил компромиссный подход к проблеме криптоанализа, позволяющий проводить анализ криптосистемы, имеющей <span class="math">N</span> ключей, за <span class="math">N^{2/3}</span> операций, с затратами по памяти также <span class="math">N^{2/3}</span>. Это становится возможным после того, как единожды будет выполнено требующее O(n) операций предварительное получение возможных ключей.</p>
<p>Идея заключается в следующем.</p>
<p>Пусть в алгоритме шифрования используется односторонняя функция <span class="math">~S_{k_i}(P)</span>. По свойствам односторонней функции получение использованного ключа <span class="math">~k_i</span> по известной паре <span class="math">~P_0,C_0</span> — трудная задача, в то время как вычисление функции от данного открытого текста — простая задача.</p>
<p>Криптоаналитик применяет атаку на основе подобранного открытого текста и получает единственный шифртекст <span class="math">~C_0</span>, соответствующий открытому тексту <span class="math">~P_0</span>:</p>
<p><center><span class="math">~C_0 = S_k(P_0)</span></center></p>
<p>Задача — найти ключ <span class="math">~k</span>, которым осуществлялось шифрование. Для этого следует найти способ вычисления возможных ключей. Введем т. н. \textbf{функцию редукции} <span class="math">~R(C)</span>, ставящую шифртексту <span class="math">~C_i</span> в соответствие некий ключ <span class="math">k_{i+1}</span> (длина ключа, как правило, меньше длины шифртекста, отсюда и термин):</p>
<p><center><span class="math">~R(C_i) = k_{i+1}</span></center></p>
<p>Вычисление функции редукции — простая операция.</p>
<p>Функция <span class="math">~f = R[S_{k_i}(P_0)]</span></p>
<p>ставит в соответствие ключу <span class="math">~k_i</span> другой ключ <span class="math">~k_{i+1}</span>.
Теперь мы можем получить сколь угодно длинную цепочку ключей:</p>
<p><center><span class="math">~k_i \stackrel{f}{\longrightarrow} k_{i+1} \stackrel{f}{\longrightarrow} k_{i+2} \stackrel{f}{\longrightarrow} ... </span></center></p>
<p>Для того, чтобы построить таблицу поиска, криптоаналитик задается <span class="math">~m</span> случайными элементами пространства ключей.
Из каждого ключа описанным выше методом получаем цепочку ключей длины <span class="math">~t</span>. В память записываем только <i>начальный</i> и <i>конечный</i> ключи каждой цепочки (пары ключей сортируем по <i>конечному</i> ключу). Таким образом, готовая таблица занимает <span class="math">O(m)</span> ячеек памяти. Генерация таблицы требует <span class="math">~mt</span> операций.</p>
<p>Имея построенную таблицу, криптоаналитик может проводить перебор следующим образом. Исходим из того, что использованный при шифровании ключ <span class="math">~k</span> встретился при генерации таблицы. В таком случае, из него не более, чем за t операций применения функции <span class="math">f</span>, можно получить один из <span class="math">m</span> конечных ключей, сохраненных в памяти.</p>
<p>После каждого применения операции редукции криптоаналитик ищет очередной полученный ключ в таблице (найти его или убедиться в его отсутствии можно за <span class="math">~log(m)</span> операций, используя бинарный поиск, так как таблица отсортирована по конечному ключу).
Встретив один из конечных ключей, можно по соответствующему ему <i>начальному</i> ключу восстановить всю соответствующую цепочку; искомый ключ является её предпоследним ключом.</p>
<p>Нахождение ключа, таким образом, занимает <span class="math">~O(t\cdot log(m))</span>; пренебрегая логарифмическим множителем, имеем <span class="math">~O(t)</span>. При этом затраты памяти на хранение таблицы составляют <span class="math">~O(m)</span>.</p>
<p>Анализ алгоритма, однако, должен учитывать, что вероятность <span class="math">~P_{success}</span> удачного дешифрования на самом деле меньше единицы, а время дешифрования может получится большим объявленного, по указанным ниже причинам.</p>

<ol>
<li>Возможны <i>слияния</i> цепочек, когда для некоторой пары индексов <span class="math">i,j</span> совпадают <span class="math">i</span>-й ключ одной и <span class="math">j</span>-й ключ другой цепочки.</li>
<li>Возможны т. н. «ложные тревоги» (англ. false alarms), когда криптоаналитик находит в таблице более одного конечного ключа. В таком случае ему приходится проверять все соответствующие цепочки.</li></ol>

<p>Может быть получены нижняя граница для вероятности успешного дешифрования:</p>
<p><center><span class="math">~P_{success} \geq \frac{1}{N} \sum\limits_{i=1}^m \sum \limits_{j=0}^{t-1} (1 - \frac{it}{N})^{j+1}</span></center></p>
<p>Приведенное выражение соответствует приближению, что функция <span class="math">~f</span> — случайная величина с равномерным распределением на множестве ключей. Впрочем, устойчивая криптосистема должна быть хорошим псевдослучайным генератором.</p>
<p>Оценка этой данного выражения приводит к следующему результату: <b>произведение <span class="math">mt^2</span> не имеет смысл брать большим, чем <span class="math">N</span></b>: в противном случае, быстро падает нижняя граница вероятности успеха.</p>
<p>При <span class="math">mt^2 = N</span> мы получим</p>
<p><center><span class="math">P_{success} \geq 0.8 \frac{mt}{N} = \frac{1}{t}</span></center></p>
<p>Криптоаналитик может теперь может сгенерировать не одну, а <span class="math">~l</span> таблиц, в каждой таблице использовав свою функцию редукции (что позволит избежать слияний цепочек из разных таблиц). При этом нижняя граница вероятности успешного дешифрования составит:</p>
<p><center><span class="math">~P_{success,l} \geq 1 - [\frac{1}{N} \sum\limits_{i=1}^m \sum \limits_{j=0}^{t-1} (1 - \frac{it}{N})^{j+1}]^l</span></center></p>
<p>Выбрав <span class="math">l=t</span>, криптоаналитик получает затраты <span class="math">mt</span> по памяти и <span class="math">t^2</span> по времени (в каждой таблице использована своя функция редукции, поэтому при дешифровании надо получать свою цепочку для каждой таблицы) при вероятности успеха, близкой к единице[сноска, объясняющая почему будет мало и число ложных тревог и ссылка на Хеллмана]. Взяв <span class="math">t=m=N^{1/3}</span>, получим требуемые затраты <span class="math">N^{2/3}</span> по времени и памяти.</p>
<h2><span class="mw-headline" id=".D0.94.D1.80.D1.83.D0.B3.D0.B8.D0.B5_.D0.BF.D1.80.D0.B8.D0.BC.D0.B5.D1.80.D1.8B">Другие примеры</span></h2>
<p>Другие алгоритмы, которые, также, используют «выбор оптимального соотношения место-время»:</p>

<ul>
<li>Алгоритм Шенкса, применяемый для расчета дискретных логарифмов.</li>
<li>Динамическое программирование, при котором временная сложность задачи, эффектично разбивающейся на подзадачи, может быть значительно снижена путем мемоизации — сохранения уже вычисленных решений подзадач.</li>
<li>Радужные таблицы в криптографии — усовершенствованный вариант таблиц поиска для обращения криптографических хеш-функций.</li></ul>

<h2><span class="mw-headline" id=".D0.A1.D0.BC._.D1.82.D0.B0.D0.BA.D0.B6.D0.B5">См. также</span></h2>

<ul>
<li>Algorithmic efficiency</li>
<li>Computational resource</li>
<li>Blum&#39;s speedup theorem</li>
<li>Теорема Сэвича</li>
<li>Раскрутка цикла</li>
<li>Радужные таблицы</li></ul>

<h2><span class="mw-headline" id=".D0.9F.D1.80.D0.B8.D0.BC.D0.B5.D1.87.D0.B0.D0.BD.D0.B8.D1.8F">Примечания</span></h2>


<h2><span class="mw-headline" id=".D0.A1.D1.81.D1.8B.D0.BB.D0.BA.D0.B8">Ссылки</span></h2>

<ul>
<li><a class="externallink" href="http://caislab.kaist.ac.kr/lecture/2010/spring/cs548/basic/B01.pdf" rel="nofollow" title="http://caislab.kaist.ac.kr/lecture/2010/spring/cs548/basic/B01.pdf">Martin Hellman — A Cryptanalytic Time-Memory Trade-Off</a></li>
<li><a class="externallink" href="http://lasecwww.epfl.ch/pub/lasec/doc/Oech03.pdf" rel="nofollow" title="http://lasecwww.epfl.ch/pub/lasec/doc/Oech03.pdf">Philippe Oechslin — Making a Faster Cryptanalytic Time-Memory Trade-Off</a></li>
<li><a class="externallink" href="http://www.cs.sjsu.edu/faculty/stamp/RUA/TMTO.pdf" rel="nofollow" title="http://www.cs.sjsu.edu/faculty/stamp/RUA/TMTO.pdf">Mark Stamp — Once Upon a Time-Memory Tradeoff.</a></li></ul>
<p>Категория:Информатика
Категория:Криптография</p>
<p><a href="http://de.wikipedia.org/wiki/Time-Memory_Tradeoff">de:Time-Memory Tradeoff</a>
<a href="http://en.wikipedia.org/wiki/Space%E2%80%93time_tradeoff">en:Space–time tradeoff</a>
<a href="http://es.wikipedia.org/wiki/Situaci%C3%B3n_de_compromiso_espacio-tiempo">es:Situaci?n de compromiso espacio-tiempo</a>
<a href="http://fr.wikipedia.org/wiki/Compromis_temps-m%C3%A9moire">fr:Compromis temps-m?moire</a>
<a href="http://it.wikipedia.org/wiki/Compromesso_tempo-memoria">it:Compromesso tempo-memoria</a>
<a href="http://ja.wikipedia.org/wiki/%E6%99%82%E9%96%93%E3%81%A8%E7%A9%BA%E9%96%93%E3%81%AE%E3%83%88%E3%83%AC%E3%83%BC%E3%83%89%E3%82%AA%E3%83%95">ja:????????????</a>
<a href="http://simple.wikipedia.org/wiki/Space-time_tradeoff">simple:Space-time tradeoff</a>
<a href="http://uk.wikipedia.org/wiki/%D0%9F%D1%80%D0%BE%D1%81%D1%82%D0%BE%D1%80%D0%BE%D0%B2%D0%BE-%D1%87%D0%B0%D1%81%D0%BE%D0%B2%D0%B0_%D0%B4%D0%BE%D0%BC%D0%BE%D0%B2%D0%BB%D0%B5%D0%BD%D1%96%D1%81%D1%82%D1%8C">uk:Просторово-часова домовленість</a></p>
</html>